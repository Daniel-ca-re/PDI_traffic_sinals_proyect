{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def filtrar_color_amarillo(imagen):\n",
    "    # Convertir la imagen a formato HSV (Hue, Saturation, Value)\n",
    "    hsv = cv2.cvtColor(imagen, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Definir el rango de colores amarillos en HSV\n",
    "    lower_yellow = np.array([18, 100, 100])\n",
    "    upper_yellow = np.array([32, 255, 255])\n",
    "    \n",
    "    # Aplicar el filtro para detectar solo el color amarillo\n",
    "    mask = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "    \n",
    "    # Crear una imagen binaria utilizando la máscara\n",
    "    resultado = cv2.bitwise_and(imagen, imagen, mask=mask)\n",
    "    \n",
    "    return mask, resultado\n",
    "\n",
    "def remove_small_particles(binary_image, min_area):\n",
    "    # Find contours in the binary image\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Create a mask to store the filtered particles\n",
    "    filtered_mask = np.zeros_like(binary_image)\n",
    "    \n",
    "    # Iterate through contours\n",
    "    for contour in contours:\n",
    "        # Calculate the area of the contour\n",
    "        area = cv2.contourArea(contour)\n",
    "        \n",
    "        # If the area is larger than the minimum area threshold, keep the contour\n",
    "        if area >= min_area:\n",
    "            cv2.drawContours(filtered_mask, [contour], -1, 255, cv2.FILLED)\n",
    "    \n",
    "    return filtered_mask\n",
    "\n",
    "\n",
    "def remove_small_particles2(binary_image, min_area):\n",
    "    # Find contours in the binary image\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Create lists to store positions and areas of particles\n",
    "    particle_positions = []\n",
    "    particle_areas = []\n",
    "    \n",
    "    # Create a mask to store the filtered particles\n",
    "    filtered_mask = np.zeros_like(binary_image)\n",
    "    \n",
    "    # Iterate through contours\n",
    "    for contour in contours:\n",
    "        # Calculate the area of the contour\n",
    "        area = cv2.contourArea(contour)\n",
    "        \n",
    "        # If the area is larger than the minimum area threshold, keep the contour\n",
    "        if area >= min_area:\n",
    "            # Get the centroid of the contour\n",
    "            M = cv2.moments(contour)\n",
    "            cx = int(M['m10'] / M['m00'])\n",
    "            cy = int(M['m01'] / M['m00'])\n",
    "            \n",
    "            # Append position and area to the lists\n",
    "            particle_positions.append([cx, cy])\n",
    "            particle_areas.append(area)\n",
    "            \n",
    "            # Draw the contour on the filtered mask\n",
    "            cv2.drawContours(filtered_mask, [contour], -1, 255, cv2.FILLED)\n",
    "    \n",
    "    # Convert lists to NumPy arrays\n",
    "    particle_positions = np.array(particle_positions)\n",
    "    particle_areas = np.array(particle_areas)\n",
    "    \n",
    "    return filtered_mask, particle_positions, particle_areas\n",
    "\n",
    "def expand_binary_zone(binary_image, iterations=1):\n",
    "    # Definir el kernel para la operación de dilatación\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    \n",
    "    # Aplicar la operación de dilatación\n",
    "    expanded_image = cv2.dilate(binary_image, kernel, iterations=iterations)\n",
    "    \n",
    "    return expanded_image\n",
    "\n",
    "\n",
    "\n",
    "def shrink_binary_zone(binary_image, iterations=1):\n",
    "    # Define the kernel for the erosion operation\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    \n",
    "    # Apply the erosion operation\n",
    "    shrunk_image = cv2.erode(binary_image, kernel, iterations=iterations)\n",
    "    \n",
    "    return shrunk_image\n",
    "\n",
    "def filtering_1(imagen, mode=0, dif=3):\n",
    "    mask_amarillo, resultado_amarillo = filtrar_color_amarillo(imagen)\n",
    "\n",
    "    # Set the minimum area threshold\n",
    "    height, width = mask_amarillo.shape\n",
    "    min_area_threshold = int(height*width*0.00005)\n",
    "\n",
    "    # Remove small particles from the binary image\n",
    "    filtered_image, areas, positions = remove_small_particles2(mask_amarillo, min_area_threshold)\n",
    "\n",
    "    filtered_image = expand_binary_zone(filtered_image, dif)\n",
    "    filtered_image = shrink_binary_zone(filtered_image, dif)\n",
    "\n",
    "    bordes = cv2.Canny(filtered_image, 100, 200)\n",
    "\n",
    "    # Find contours in the binary image\n",
    "    contours, _ = cv2.findContours(filtered_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # If there are contours\n",
    "    if contours:\n",
    "        # Find the largest contour\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Get the bounding rectangle of the largest contour\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "        # Calculate the center of the bounding rectangle\n",
    "        center_x = x + w // 2\n",
    "        center_y = y + h // 2\n",
    "\n",
    "        # Crop the image to the bounding rectangle\n",
    "        cropped_image = imagen[y:y+h, x:x+w]\n",
    "\n",
    "        # Display the cropped image if mode is not 0\n",
    "        if mode != 0:\n",
    "            cv2.imshow('Original', imagen)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "            cv2.imshow('Cropped Image', cropped_image)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "            cv2.imshow('Máscara Amarilla', mask_amarillo)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "            cv2.imshow('Filtered Binary Image', filtered_image)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "    return bordes, filtered_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 3):  # Suponiendo que tienes imágenes de test1.jpg a test10.jpg\n",
    "    # Formar el nombre de archivo\n",
    "    filename = f'test{i}.jpg'\n",
    "\n",
    "    # Cargar la imagen\n",
    "    image = cv2.imread(filename)\n",
    "\n",
    "    # Comprobar si la imagen se cargó correctamente\n",
    "    if image is not None:\n",
    "        filtering_1(image, mode=1)\n",
    "    else:\n",
    "        print(f'No se pudo cargar la imagen {filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRUEBAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Cargar la imagen\n",
    "image = cv2.imread('test1.jpg')\n",
    "cv2.imshow('Imagen original', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Convertir la imagen a espacio de color HSV\n",
    "hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "cv2.imshow('Imagen HSV', hsv_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Definir el rango de colores de la señal de tráfico en HSV\n",
    "lower_yellow = np.array([18, 100, 100])\n",
    "upper_yellow = np.array([32, 255, 255])\n",
    "\n",
    "# Crear una máscara para los colores dentro del rango especificado\n",
    "mask = cv2.inRange(hsv_image, lower_yellow, upper_yellow)\n",
    "cv2.imshow('Máscara', mask)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Aplicar operaciones de morfología para mejorar la detección y rellenar el contorno de amarillo\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "# Cierre para rellenar pequeños huecos dentro del contorno amarillo\n",
    "mask_closed = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "# Apertura para eliminar detalles no deseados fuera del contorno amarillo\n",
    "mask_cleaned = cv2.morphologyEx(mask_closed, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# Encuentra contornos en la máscara limpia\n",
    "contours, _ = cv2.findContours(mask_cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Crea una máscara en blanco del mismo tamaño que la imagen original\n",
    "filled_contour_mask = np.zeros_like(mask_cleaned)\n",
    "\n",
    "# Dibuja los contornos en la máscara en blanco (rellenándolos)\n",
    "cv2.drawContours(filled_contour_mask, contours, -1, (255), thickness=cv2.FILLED)\n",
    "\n",
    "# Muestra la máscara después de aplicar la morfología y rellenar los contornos amarillos\n",
    "cv2.imshow('Máscara después de morfología y relleno', filled_contour_mask)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Encontrar contornos en la máscara\n",
    "contours, _ = cv2.findContours(filled_contour_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Encontrar el contorno más grande\n",
    "largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "# Dibujar un rectángulo alrededor del contorno más grande\n",
    "x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "# Mostrar la imagen con las señales de tráfico resaltadas\n",
    "cv2.imshow('Señal de tráfico resaltada', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, roc_curve, precision_recall_curve, f1_score\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Aquí deberías tener tus etiquetas reales y predicciones\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# labels = etiquetas reales\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# predictions = predicciones del modelo\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Porcentaje de error\u001b[39;00m\n\u001b[0;32m     10\u001b[0m error_rate \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(labels \u001b[38;5;241m!=\u001b[39m predictions) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, precision_recall_curve, f1_score\n",
    "\n",
    "# Aquí deberías tener tus etiquetas reales y predicciones\n",
    "# labels = etiquetas reales\n",
    "# predictions = predicciones del modelo\n",
    "\n",
    "# Porcentaje de error\n",
    "error_rate = np.mean(labels != predictions) * 100\n",
    "print(\"Porcentaje de error: {:.2f}%\".format(error_rate))\n",
    "\n",
    "# Matriz de confusión\n",
    "conf_matrix = confusion_matrix(labels, predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Etiqueta Predicha')\n",
    "plt.ylabel('Etiqueta Real')\n",
    "plt.show()\n",
    "\n",
    "# Curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(labels, predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='Curva ROC')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Curva de precisión-recuperación\n",
    "precision, recall, _ = precision_recall_curve(labels, predictions)\n",
    "f1 = f1_score(labels, predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, color='blue', lw=2, label='Curva Precisión-Recuperación')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Curva Precisión-Recuperación')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Cargar la imagen base y convertirla a escala de grises\n",
    "base_image = cv2.imread('Rombo.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Binarizar la imagen base (opcional, dependiendo del preprocesamiento necesario)\n",
    "_, base_thresholded = cv2.threshold(base_image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Encontrar contornos en la imagen base\n",
    "base_contours, _ = cv2.findContours(base_thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Supongamos que solo hay un contorno en la imagen base\n",
    "base_contour = base_contours[0]\n",
    "\n",
    "# Cargar la imagen donde deseas detectar las señales de tráfico\n",
    "input_image = cv2.imread('test3.jpg')\n",
    "\n",
    "# Convertir la imagen de entrada a escala de grises\n",
    "input_gray = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Binarizar la imagen de entrada (opcional, dependiendo del preprocesamiento necesario)\n",
    "_, input_thresholded = cv2.threshold(input_gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Detección de contornos en la imagen de entrada\n",
    "contours, _ = cv2.findContours(input_thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Iterar sobre los contornos detectados\n",
    "for contour in contours:\n",
    "    # Calcula la similitud entre el contorno actual y el contorno de la imagen base\n",
    "    similarity = cv2.matchShapes(contour, base_contour, cv2.CONTOURS_MATCH_I1, 0.0)\n",
    "    \n",
    "    # Define un umbral de similitud para filtrar los contornos\n",
    "    threshold_similarity = 0.1\n",
    "    \n",
    "    # Si la similitud es mayor que el umbral, dibuja el contorno en la imagen de entrada\n",
    "    if similarity < threshold_similarity:\n",
    "        cv2.drawContours(input_image, [contour], -1, (0, 255, 0), 2)\n",
    "\n",
    "# Muestra la imagen de entrada con los contornos de las señales de tráfico detectadas\n",
    "cv2.imshow('Señales de tráfico detectadas', input_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skimage library not found. Please install it using:\n",
      "pip install scikit-image\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m input_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest7.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Convertir las imágenes a espacio de color HSV\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m reference_hsv \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreference_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2HSV\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m input_hsv \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(input_image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2HSV)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Definir rangos de color para la señal de tráfico (ajustar según la señal)\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "try:\n",
    "    from skimage import measure\n",
    "except ModuleNotFoundError:\n",
    "    print(\"Skimage library not found. Please install it using:\")\n",
    "    print(\"pip install scikit-image\")\n",
    "    exit()\n",
    "# Cargar las imágenes\n",
    "reference_image = cv2.imread('referencia.jpg')\n",
    "input_image = cv2.imread('test7.jpg')\n",
    "\n",
    "# Convertir las imágenes a espacio de color HSV\n",
    "reference_hsv = cv2.cvtColor(reference_image, cv2.COLOR_BGR2HSV)\n",
    "input_hsv = cv2.cvtColor(input_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Definir rangos de color para la señal de tráfico (ajustar según la señal)\n",
    "lower_yellow = np.array([20, 100, 100], dtype=\"uint8\")\n",
    "upper_yellow = np.array([30, 255, 255], dtype=\"uint8\")\n",
    "\n",
    "# Crear máscaras para la señal de tráfico en ambas imágenes\n",
    "reference_mask = cv2.inRange(reference_hsv, lower_yellow, upper_yellow)\n",
    "input_mask = cv2.inRange(input_hsv, lower_yellow, upper_yellow)\n",
    "\n",
    "# Aplicar técnicas de segmentación de imagen (opcional)\n",
    "# Puedes aplicar técnicas como `morphological operations` o `watershed segmentation` para mejorar la segmentación de la señal de tráfico.\n",
    "\n",
    "# Encontrar regiones de interés (regiones) en la imagen de referencia\n",
    "reference_regions = measure.regionprops(reference_mask, properties=('area', 'major_axis_length', 'minor_axis_length'))\n",
    "\n",
    "# Inicializar variables para la señal de tráfico en la imagen de entrada\n",
    "best_similarity = 0.0\n",
    "best_contour = None\n",
    "\n",
    "# Iterar sobre las regiones de interés en la imagen de entrada\n",
    "for region in measure.regionprops(input_mask, properties=('area', 'major_axis_length', 'minor_axis_length')):\n",
    "    # Calcular la similitud entre la región actual y las regiones de la imagen de referencia\n",
    "    for reference_region in reference_regions:\n",
    "        similarity = calculate_similarity(region, reference_region)  # Implementar la función `calculate_similarity`\n",
    "        if similarity > best_similarity:\n",
    "            best_similarity = similarity\n",
    "            best_contour = region.bbox\n",
    "\n",
    "# Dibujar el contorno de la señal de tráfico detectada (si se encontró)\n",
    "if best_contour is not None:\n",
    "    x, y, w, h = best_contour\n",
    "    cv2.rectangle(input_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "# Visualizar la imagen resultante\n",
    "cv2.imshow('Señal de tráfico detectada', input_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
